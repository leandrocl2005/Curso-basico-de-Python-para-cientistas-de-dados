{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Classificação supervisionada com Titanic</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Este tutorial é um tradução e adaptação para Python 3 daquele encontrado no blog do <a href=\"http://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html\">ahmedbesbes</a>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto de dados pode ser encontrado em https://www.kaggle.com/competitions/titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicas para melhorar o score\n",
    "\n",
    "- Teste outros tipos de normalização\n",
    "- Compare os modelos já tunados previamente (toma bastante tempo)\n",
    "- Evite dummies trap\n",
    "- Use redes neurais (Futuro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estrutura de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# estatistica\n",
    "from scipy.stats import skew\n",
    "\n",
    "# metricas\n",
    "from sklearn.metrics import accuracy_score # acurácia\n",
    "# https://en.wikipedia.org/wiki/Accuracy_and_precision\n",
    "# https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "\n",
    "# normalizador\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# treino teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# modelos\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# tunagem\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# stack\n",
    "from mlxtend.regressor import StackingCVRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remover warning (opcional e não recomendado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Carregando treino e teste</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../datasets/titanic/train.csv')\n",
    "test = pd.read_csv('../datasets/titanic/test.csv')\n",
    "all_data = pd.concat((\n",
    "    train.loc[:,'Pclass':],\n",
    "     test.loc[:,'Pclass':]))\n",
    "y = train['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 0 to 417\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    1309 non-null   int64  \n",
      " 1   Name      1309 non-null   object \n",
      " 2   Sex       1309 non-null   object \n",
      " 3   Age       1046 non-null   float64\n",
      " 4   SibSp     1309 non-null   int64  \n",
      " 5   Parch     1309 non-null   int64  \n",
      " 6   Ticket    1309 non-null   object \n",
      " 7   Fare      1308 non-null   float64\n",
      " 8   Cabin     295 non-null    object \n",
      " 9   Embarked  1307 non-null   object \n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 112.5+ KB\n"
     ]
    }
   ],
   "source": [
    "all_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessa vez vamos processar cada variável separadamente para uma melhor preparação para modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare',\n",
       "       'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PClass (apesar de numérico) -> dummies\n",
    "# Names -> *transformar em títulos* e dummies\n",
    "# Age -> preencher com média por grupos\n",
    "# Sex -> Dummies\n",
    "# SibSp e Parch -> transformar em tamanho da família\n",
    "# Ticket -> Manter só as letras\n",
    "# Fare -> preencher nulos com média\n",
    "# Cabin -> transformar em deck, preencher nulos com U e dummies\n",
    "# Embarked -> preencher nulos com a moda e depois dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name (parte 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Title'] = all_data['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
    "title_map = {\n",
    "    \"Capt\":       \"Officer\",\n",
    "    \"Col\":        \"Officer\",\n",
    "    \"Major\":      \"Officer\",\n",
    "    \"Jonkheer\":   \"Royalty\",\n",
    "    \"Don\":        \"Royalty\",\n",
    "    \"Sir\" :       \"Royalty\",\n",
    "    \"Dr\":         \"Officer\",\n",
    "    \"Rev\":        \"Officer\",\n",
    "    \"the Countess\":\"Royalty\",\n",
    "    \"Dona\":       \"Royalty\",\n",
    "    \"Mme\":        \"Mrs\",\n",
    "    \"Mlle\":       \"Miss\",\n",
    "    \"Ms\":         \"Mrs\",\n",
    "    \"Mr\" :        \"Mr\",\n",
    "    \"Mrs\" :       \"Mrs\",\n",
    "    \"Miss\" :      \"Miss\",\n",
    "    \"Master\" :    \"Master\",\n",
    "    \"Lady\" :      \"Royalty\"\n",
    "}\n",
    "all_data['Title'] = all_data['Title'].map(title_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillAges(row):\n",
    "    if row['Sex']=='female' and row['Pclass'] == 1:\n",
    "        if row['Title'] == 'Miss':\n",
    "            return 30\n",
    "        elif row['Title'] == 'Mrs':\n",
    "            return 45\n",
    "        elif row['Title'] == 'Officer':\n",
    "            return 49\n",
    "        elif row['Title'] == 'Royalty':\n",
    "            return 39\n",
    "\n",
    "    elif row['Sex']=='female' and row['Pclass'] == 2:\n",
    "        if row['Title'] == 'Miss':\n",
    "            return 20\n",
    "        elif row['Title'] == 'Mrs':\n",
    "            return 30\n",
    "\n",
    "    elif row['Sex']=='female' and row['Pclass'] == 3:\n",
    "        if row['Title'] == 'Miss':\n",
    "            return 18\n",
    "        elif row['Title'] == 'Mrs':\n",
    "            return 31\n",
    "\n",
    "    elif row['Sex']=='male' and row['Pclass'] == 1:\n",
    "        if row['Title'] == 'Master':\n",
    "            return 6\n",
    "        elif row['Title'] == 'Mr':\n",
    "            return 41.5\n",
    "        elif row['Title'] == 'Officer':\n",
    "            return 52\n",
    "        elif row['Title'] == 'Royalty':\n",
    "            return 40\n",
    "\n",
    "    elif row['Sex']=='male' and row['Pclass'] == 2:\n",
    "        if row['Title'] == 'Master':\n",
    "            return 2\n",
    "        elif row['Title'] == 'Mr':\n",
    "            return 30\n",
    "        elif row['Title'] == 'Officer':\n",
    "            return 41.5\n",
    "\n",
    "    elif row['Sex']=='male' and row['Pclass'] == 3:\n",
    "        if row['Title'] == 'Master':\n",
    "            return 6\n",
    "        elif row['Title'] == 'Mr':\n",
    "            return 26\n",
    "all_data[\"Age\"] = all_data.apply(lambda r : fillAges(r) if np.isnan(r['Age']) else r['Age'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name (parte 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.drop('Name',axis=1,inplace=True)\n",
    "titles_dummies = pd.get_dummies(all_data['Title'], prefix='Title')\n",
    "all_data = pd.concat([all_data, titles_dummies],axis=1)\n",
    "all_data.drop('Title',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"Sex\"] = all_data[\"Sex\"].map(lambda x: 1 if x == 'male' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SibSp e Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['FamilySize'] = all_data['Parch'] + all_data['SibSp'] + 1 # (+1 o próprio cara)\n",
    "# introducing other features based on the family size\n",
    "all_data['Singleton'] = all_data['FamilySize'].map(lambda s : 1 if s == 1 else 0)\n",
    "all_data['SmallFamily'] = all_data['FamilySize'].map(lambda s : 1 if 2<=s<=4 else 0)\n",
    "all_data['LargeFamily'] = all_data['FamilySize'].map(lambda s : 1 if 5<=s else 0)\n",
    "\n",
    "all_data.drop(\"SibSp\", axis=1, inplace=True)\n",
    "all_data.drop(\"Parch\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Ticket'] = all_data['Ticket'].map(lambda x: ''.join(filter(str.isalpha, x)))\n",
    "all_data['Ticket'] = all_data['Ticket'].map(lambda x: x if x else \"XXX\")\n",
    "tickets_dummies = pd.get_dummies(all_data['Ticket'],prefix='Ticket')\n",
    "all_data = pd.concat([all_data, tickets_dummies],axis=1)\n",
    "all_data.drop('Ticket',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_mean = all_data[\"Fare\"].mean()\n",
    "all_data[\"Fare\"] = all_data[\"Fare\"].fillna(fare_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"Cabin\"] = all_data[\"Cabin\"].fillna(\"U\")\n",
    "all_data[\"Cabin\"] = all_data[\"Cabin\"].map(lambda x: x[0])\n",
    "cabin_dummies = pd.get_dummies(all_data['Cabin'],prefix='Cabin')\n",
    "all_data = pd.concat([all_data, cabin_dummies],axis=1)\n",
    "all_data.drop('Cabin',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_mode = all_data[\"Embarked\"].mode()\n",
    "all_data[\"Embarked\"] = all_data[\"Embarked\"].fillna(embarked_mode)\n",
    "embarked_dummies = pd.get_dummies(all_data['Embarked'],prefix='Embarked')\n",
    "all_data = pd.concat([all_data, embarked_dummies],axis=1)\n",
    "all_data.drop('Embarked',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removendo assimetria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log(x+1) nas features númericas para obter distribuição de fequência mais próxima da normal\n",
    "\n",
    "# selecionando features numéricas\n",
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "# calculando skew (assimetria)\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
    "# filtro por skew maior que 0.75 (perto de zero é normal)\n",
    "skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "# selecionando índices para normalização\n",
    "skewed_feats = skewed_feats.index\n",
    "# normalizando por log(x + 1)\n",
    "all_data[skewed_feats] = np.log1p(all_data[skewed_feats]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(all_data.columns)\n",
    "all_data[features] = all_data[features].apply(lambda x: x/x.max(), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treino e Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data[:train.shape[0]] # treino\n",
    "test = all_data[train.shape[0]:] # teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instances = [\n",
    "    (RandomForestClassifier(), \"RandomForestClassifier\"),\n",
    "    (ExtraTreesClassifier(), \"ExtraTreesClassifier\"),\n",
    "    (GradientBoostingClassifier(), \"GradientBoostingClassifier\"),\n",
    "    (LogisticRegression(), \"LogisticRegression\"),\n",
    "    (DecisionTreeClassifier(), \"DecisionTreeClassifier\"),\n",
    "    (KNeighborsClassifier(), \"KNeighborsClassifier\"),\n",
    "    (GaussianNB(), \"GaussianNB\"),\n",
    "    (Perceptron(), \"Perceptron\"),\n",
    "    (SGDClassifier(), \"SGDClassifier\"),\n",
    "    (SVC(), \"SVC\"),\n",
    "    (LinearSVC(), \"LinearSVC\"),\n",
    "    (LGBMClassifier(verbose=0), \"LGBMClassifier\"),\n",
    "    (XGBClassifier(), \"XGBClassifier\"),\n",
    "    (CatBoostClassifier(verbose=False), \"CatBoostClassifier\"), \n",
    "] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Model\":[],\n",
    "    \"ACC\":[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "for model, model_name in model_instances:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results['Model'].append(model_name)\n",
    "    results['ACC'].append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.834081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.820628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.793722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.820628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.807175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.820628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.461883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.811659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.780269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.829596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.825112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.798206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.816143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.834081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model       ACC\n",
       "0       RandomForestClassifier  0.834081\n",
       "1         ExtraTreesClassifier  0.820628\n",
       "2   GradientBoostingClassifier  0.793722\n",
       "3           LogisticRegression  0.820628\n",
       "4       DecisionTreeClassifier  0.807175\n",
       "5         KNeighborsClassifier  0.820628\n",
       "6                   GaussianNB  0.461883\n",
       "7                   Perceptron  0.811659\n",
       "8                SGDClassifier  0.780269\n",
       "9                          SVC  0.829596\n",
       "10                   LinearSVC  0.825112\n",
       "11              LGBMClassifier  0.798206\n",
       "12               XGBClassifier  0.816143\n",
       "13          CatBoostClassifier  0.834081"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     RandomForestClassifier\n",
       "13        CatBoostClassifier\n",
       "9                        SVC\n",
       "10                 LinearSVC\n",
       "1       ExtraTreesClassifier\n",
       "Name: Model, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_temp = results.sort_values(\"ACC\", ascending=False)\n",
    "results_temp.iloc[:5][\"Model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Tunagem de hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8353832342049152\n",
      "Best parameters: {'criterion': 'gini', 'max_depth': 18, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "# Escolha dos melhores parâmetros\n",
    "randomForest = RandomForestClassifier()\n",
    "cross_validation = StratifiedKFold(n_splits=5) # n_folds deve ser escolhido de forma precisa\n",
    "parameter_grid = {\n",
    "     'max_depth' : [15,16],\n",
    "     'n_estimators': [10000,20000,30000],\n",
    "     'criterion': ['gini','entropy',],\n",
    "     'min_samples_split': [27,28], # tunado\n",
    "     'max_features':[6,7,8]\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    randomForest,\n",
    "    param_grid=parameter_grid,\n",
    "    cv=cross_validation)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submissão para o Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=10000, # tunado\n",
    "    criterion='entropy', # tunado\n",
    "    max_depth=9, # tunado\n",
    "    min_samples_split=27, # tunado\n",
    "    max_features=8)\n",
    "\n",
    "random_forest.fit(X, y)\n",
    "y_pred = random_forest.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=20, # tunado\n",
    "    max_depth=9)\n",
    "\n",
    "random_forest.fit(X, y)\n",
    "y_pred = random_forest.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"../datasets/titanic/gender_submission.csv\",index_col=0)\n",
    "sample_submission['Survived'] = y_pred\n",
    "sample_submission.to_csv(\"random_forest_tunado_x.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Pontuação no Kaggle:</b> Your submission scored 0.78299."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tunar outros modelos <a href='http://scikit-learn.org/stable/modules/grid_search.html'>Tuning the hyper-parameters of an estimator</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Resumo das pontuações com modelos tunados Kaggle:</p>\n",
    "<table cellspacing=\"2\" cellpadding=\"4\" style=\"border:solid 2px; margin:auto;\" >\n",
    "    <tr style=\"border:solid 2px;\">\n",
    "          <td height='50' bgcolor='#D4D0C8' style=\"border:solid 2px;\"><b>Submission</td>\n",
    "          <td height='50' bgcolor='#D4D0C8' style=\"border:solid 2px;\"><b>Score</td>\n",
    "    </tr>\n",
    "    <tr style=\"border:solid 2px;\">\n",
    "        <td style=\"border:solid 2px;\"> random_forest_tunado.csv </td>\n",
    "        <td style=\"border:solid 2px;\">0.80383</td>\n",
    "    </tr>\n",
    "    <tr style=\"border:solid 2px;\">\n",
    "        <td style=\"border:solid 2px;\"> extra_trees_tunado.csv </td>\n",
    "        <td style=\"border:solid 2px;\">0.79426</td>\n",
    "    </tr>\n",
    "    <tr style=\"border:solid 2px;\">\n",
    "        <td style=\"border:solid 2px;\"> log_reg_tunado.csv </td>\n",
    "        <td style=\"border:solid 2px;\"> 0.77990</td>\n",
    "    </tr>\n",
    "    <tr style=\"border:solid 2px;\">\n",
    "        <td style=\"border:solid 2px;\"> decision_tree_tunado.csv </td>\n",
    "        <td style=\"border:solid 2px;\"> 0.76555</td>\n",
    "    </tr>\n",
    "    <tr style=\"border:solid 2px;\">\n",
    "        <td style=\"border:solid 2px;\"> grad_boost_tunado.csv </td>\n",
    "        <td style=\"border:solid 2px;\"> 0.62201</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Faça a tunagem dos modelos Light GBM, XGBoost e CatBoost. Os scores tiveram melhoras?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Faça um stack dos 3 melhores modelos que você tunou. Os scores tiveram melhoras?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Simulado! Nossa próxima atividade avaliativa será sobre classificação supervisionada. Faremos uma simulação usando o Titanic! Qual seria sua nota?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suponha que seu score é S:\n",
    "\n",
    "- Se S < 0.67, seus pontos seriam (1 - (S - 0.67)/0.67) * 4\n",
    "- Se 0.67 <= S <= 0.73, seus pontos seriam proporcionais no intervalo de 4 a 7.\n",
    "- Se 0.73 <= S <= 0.83, seus pontos seriam proporcionais no intervalo de 7 a 10.\n",
    "\n",
    "Boa sorte no simulado!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
