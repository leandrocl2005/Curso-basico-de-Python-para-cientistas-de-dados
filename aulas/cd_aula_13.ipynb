{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Classificação supervisionada com Titanic</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Este tutorial é um tradução e adaptação para Python 3 daquele encontrado no blog do <a href=\"http://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html\">ahmedbesbes</a>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto de dados pode ser encontrado em https://www.kaggle.com/competitions/titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicas para melhorar o score\n",
    "\n",
    "- Teste outros tipos de normalização\n",
    "- Compare os modelos já tunados previamente (toma bastante tempo)\n",
    "- Evite dummies trap\n",
    "- Use redes neurais (Futuro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estrutura de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# estatistica\n",
    "from scipy.stats import skew\n",
    "\n",
    "# metricas\n",
    "from sklearn.metrics import accuracy_score # acurácia\n",
    "# https://en.wikipedia.org/wiki/Accuracy_and_precision\n",
    "# https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "\n",
    "# normalizador\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# treino teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# modelos\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# tunagem\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# stack\n",
    "from mlxtend.classifier import StackingCVClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remover warning (opcional e não recomendado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Carregando treino e teste</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../datasets/titanic/train.csv')\n",
    "test = pd.read_csv('../datasets/titanic/test.csv')\n",
    "all_data = pd.concat((\n",
    "    train.loc[:,'Pclass':],\n",
    "     test.loc[:,'Pclass':]))\n",
    "y = train['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 0 to 417\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    1309 non-null   int64  \n",
      " 1   Name      1309 non-null   object \n",
      " 2   Sex       1309 non-null   object \n",
      " 3   Age       1046 non-null   float64\n",
      " 4   SibSp     1309 non-null   int64  \n",
      " 5   Parch     1309 non-null   int64  \n",
      " 6   Ticket    1309 non-null   object \n",
      " 7   Fare      1308 non-null   float64\n",
      " 8   Cabin     295 non-null    object \n",
      " 9   Embarked  1307 non-null   object \n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 112.5+ KB\n"
     ]
    }
   ],
   "source": [
    "all_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessa vez vamos processar cada variável separadamente para uma melhor preparação para modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare',\n",
       "       'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PClass (apesar de numérico) -> dummies\n",
    "# Names -> *transformar em títulos* e dummies\n",
    "# Age -> preencher com média por grupos\n",
    "# Sex -> Dummies\n",
    "# SibSp e Parch -> transformar em tamanho da família\n",
    "# Ticket -> Manter só as letras\n",
    "# Fare -> preencher nulos com média\n",
    "# Cabin -> transformar em deck, preencher nulos com U e dummies\n",
    "# Embarked -> preencher nulos com a moda e depois dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name (parte 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Title'] = all_data['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
    "title_map = {\n",
    "    \"Capt\":       \"Officer\",\n",
    "    \"Col\":        \"Officer\",\n",
    "    \"Major\":      \"Officer\",\n",
    "    \"Jonkheer\":   \"Royalty\",\n",
    "    \"Don\":        \"Royalty\",\n",
    "    \"Sir\" :       \"Royalty\",\n",
    "    \"Dr\":         \"Officer\",\n",
    "    \"Rev\":        \"Officer\",\n",
    "    \"the Countess\":\"Royalty\",\n",
    "    \"Dona\":       \"Royalty\",\n",
    "    \"Mme\":        \"Mrs\",\n",
    "    \"Mlle\":       \"Miss\",\n",
    "    \"Ms\":         \"Mrs\",\n",
    "    \"Mr\" :        \"Mr\",\n",
    "    \"Mrs\" :       \"Mrs\",\n",
    "    \"Miss\" :      \"Miss\",\n",
    "    \"Master\" :    \"Master\",\n",
    "    \"Lady\" :      \"Royalty\"\n",
    "}\n",
    "all_data['Title'] = all_data['Title'].map(title_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillAges(row):\n",
    "    if row['Sex']=='female' and row['Pclass'] == 1:\n",
    "        if row['Title'] == 'Miss':\n",
    "            return 30\n",
    "        elif row['Title'] == 'Mrs':\n",
    "            return 45\n",
    "        elif row['Title'] == 'Officer':\n",
    "            return 49\n",
    "        elif row['Title'] == 'Royalty':\n",
    "            return 39\n",
    "\n",
    "    elif row['Sex']=='female' and row['Pclass'] == 2:\n",
    "        if row['Title'] == 'Miss':\n",
    "            return 20\n",
    "        elif row['Title'] == 'Mrs':\n",
    "            return 30\n",
    "\n",
    "    elif row['Sex']=='female' and row['Pclass'] == 3:\n",
    "        if row['Title'] == 'Miss':\n",
    "            return 18\n",
    "        elif row['Title'] == 'Mrs':\n",
    "            return 31\n",
    "\n",
    "    elif row['Sex']=='male' and row['Pclass'] == 1:\n",
    "        if row['Title'] == 'Master':\n",
    "            return 6\n",
    "        elif row['Title'] == 'Mr':\n",
    "            return 41.5\n",
    "        elif row['Title'] == 'Officer':\n",
    "            return 52\n",
    "        elif row['Title'] == 'Royalty':\n",
    "            return 40\n",
    "\n",
    "    elif row['Sex']=='male' and row['Pclass'] == 2:\n",
    "        if row['Title'] == 'Master':\n",
    "            return 2\n",
    "        elif row['Title'] == 'Mr':\n",
    "            return 30\n",
    "        elif row['Title'] == 'Officer':\n",
    "            return 41.5\n",
    "\n",
    "    elif row['Sex']=='male' and row['Pclass'] == 3:\n",
    "        if row['Title'] == 'Master':\n",
    "            return 6\n",
    "        elif row['Title'] == 'Mr':\n",
    "            return 26\n",
    "all_data[\"Age\"] = all_data.apply(lambda r : fillAges(r) if np.isnan(r['Age']) else r['Age'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name (parte 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.drop('Name',axis=1,inplace=True)\n",
    "titles_dummies = pd.get_dummies(all_data['Title'], prefix='Title',dtype=int)\n",
    "all_data = pd.concat([all_data, titles_dummies],axis=1)\n",
    "all_data.drop('Title',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"Sex\"] = all_data[\"Sex\"].map(lambda x: 1 if x == 'male' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SibSp e Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['FamilySize'] = all_data['Parch'] + all_data['SibSp'] + 1 # (+1 o próprio cara)\n",
    "# introducing other features based on the family size\n",
    "all_data['Singleton'] = all_data['FamilySize'].map(lambda s : 1 if s == 1 else 0)\n",
    "all_data['SmallFamily'] = all_data['FamilySize'].map(lambda s : 1 if 2<=s<=4 else 0)\n",
    "all_data['LargeFamily'] = all_data['FamilySize'].map(lambda s : 1 if 5<=s else 0)\n",
    "\n",
    "all_data.drop(\"SibSp\", axis=1, inplace=True)\n",
    "all_data.drop(\"Parch\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Ticket'] = all_data['Ticket'].map(lambda x: ''.join(filter(str.isalpha, x)))\n",
    "all_data['Ticket'] = all_data['Ticket'].map(lambda x: x if x else \"XXX\")\n",
    "tickets_dummies = pd.get_dummies(all_data['Ticket'],prefix='Ticket',dtype=int)\n",
    "all_data = pd.concat([all_data, tickets_dummies],axis=1)\n",
    "all_data.drop('Ticket',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_mean = all_data[\"Fare\"].mean()\n",
    "all_data[\"Fare\"] = all_data[\"Fare\"].fillna(fare_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"Cabin\"] = all_data[\"Cabin\"].fillna(\"U\")\n",
    "all_data[\"Cabin\"] = all_data[\"Cabin\"].map(lambda x: x[0])\n",
    "cabin_dummies = pd.get_dummies(all_data['Cabin'],prefix='Cabin',dtype=int)\n",
    "all_data = pd.concat([all_data, cabin_dummies],axis=1)\n",
    "all_data.drop('Cabin',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_mode = all_data[\"Embarked\"].mode()\n",
    "all_data[\"Embarked\"] = all_data[\"Embarked\"].fillna(embarked_mode)\n",
    "embarked_dummies = pd.get_dummies(all_data['Embarked'],prefix='Embarked',dtype=int)\n",
    "all_data = pd.concat([all_data, embarked_dummies],axis=1)\n",
    "all_data.drop('Embarked',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removendo assimetria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log(x+1) nas features númericas para obter distribuição de fequência mais próxima da normal\n",
    "\n",
    "# selecionando features numéricas\n",
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "# calculando skew (assimetria)\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
    "# filtro por skew maior que 0.75 (perto de zero é normal)\n",
    "skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "# selecionando índices para normalização\n",
    "skewed_feats = skewed_feats.index\n",
    "# normalizando por log(x + 1)\n",
    "all_data[skewed_feats] = np.log1p(all_data[skewed_feats]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(all_data.columns)\n",
    "all_data[features] = all_data[features].apply(lambda x: x/x.max(), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treino e Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data[:train.shape[0]] # treino\n",
    "test = all_data[train.shape[0]:] # teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instances = [\n",
    "    (RandomForestClassifier(), \"RandomForestClassifier\"),\n",
    "    (ExtraTreesClassifier(), \"ExtraTreesClassifier\"),\n",
    "    (GradientBoostingClassifier(), \"GradientBoostingClassifier\"),\n",
    "    (LogisticRegression(), \"LogisticRegression\"),\n",
    "    (DecisionTreeClassifier(), \"DecisionTreeClassifier\"),\n",
    "    (KNeighborsClassifier(), \"KNeighborsClassifier\"),\n",
    "    (GaussianNB(), \"GaussianNB\"),\n",
    "    (Perceptron(), \"Perceptron\"),\n",
    "    (SGDClassifier(), \"SGDClassifier\"),\n",
    "    (SVC(), \"SVC\"),\n",
    "    (LinearSVC(), \"LinearSVC\"),\n",
    "    (LGBMClassifier(verbose=0), \"LGBMClassifier\"),\n",
    "    (XGBClassifier(), \"XGBClassifier\"),\n",
    "    (CatBoostClassifier(verbose=False), \"CatBoostClassifier\"), \n",
    "] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Model\":[],\n",
    "    \"ACC\":[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, model_name in model_instances:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results['Model'].append(model_name)\n",
    "    results['ACC'].append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_temp = results.sort_values(\"ACC\", ascending=False)\n",
    "results_temp.iloc[:5][\"Model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [100,200,300,500,1000]:\n",
    "    model = RandomForestClassifier(n_estimators=n)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(n, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Tunagem de hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Escolha dos melhores parâmetros\n",
    "randomForest = RandomForestClassifier()\n",
    "cross_validation = StratifiedKFold(n_splits=5) # n_folds deve ser escolhido de forma precisa\n",
    "parameter_grid = {\n",
    "     'max_depth' : [10,20,30],\n",
    "     'n_estimators': [100, 300,500],\n",
    "     'criterion': ['gini','entropy',],\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    randomForest,\n",
    "    param_grid=parameter_grid,\n",
    "    cv=cross_validation)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submissão para o Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=500, # tunado\n",
    "    criterion='entropy', # tunado\n",
    "    max_depth=10, # tunado\n",
    ")\n",
    "\n",
    "random_forest.fit(X, y)\n",
    "y_pred = random_forest.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"../datasets/titanic/gender_submission.csv\",index_col=0)\n",
    "sample_submission['Survived'] = y_pred\n",
    "sample_submission.to_csv(\"random_forest_tunado_aula2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Pontuação no Kaggle:</b> Your submission scored 0.78299."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tunar outros modelos <a href='http://scikit-learn.org/stable/modules/grid_search.html'>Tuning the hyper-parameters of an estimator</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Resumo das pontuações com modelos tunados Kaggle:</p>\n",
    "<table cellspacing=\"2\" cellpadding=\"4\" style=\"border:solid 2px; margin:auto;\" >\n",
    "    <tr style=\"border:solid 2px;\">\n",
    "          <td height='50' bgcolor='#D4D0C8' style=\"border:solid 2px;\"><b>Submission</td>\n",
    "          <td height='50' bgcolor='#D4D0C8' style=\"border:solid 2px;\"><b>Score</td>\n",
    "    </tr>\n",
    "    <tr style=\"border:solid 2px;\">\n",
    "        <td style=\"border:solid 2px;\"> random_forest_tunado.csv </td>\n",
    "        <td style=\"border:solid 2px;\">0.80383</td>\n",
    "    </tr>\n",
    "    <tr style=\"border:solid 2px;\">\n",
    "        <td style=\"border:solid 2px;\"> extra_trees_tunado.csv </td>\n",
    "        <td style=\"border:solid 2px;\">0.79426</td>\n",
    "    </tr>\n",
    "    <tr style=\"border:solid 2px;\">\n",
    "        <td style=\"border:solid 2px;\"> log_reg_tunado.csv </td>\n",
    "        <td style=\"border:solid 2px;\"> 0.77990</td>\n",
    "    </tr>\n",
    "    <tr style=\"border:solid 2px;\">\n",
    "        <td style=\"border:solid 2px;\"> decision_tree_tunado.csv </td>\n",
    "        <td style=\"border:solid 2px;\"> 0.76555</td>\n",
    "    </tr>\n",
    "    <tr style=\"border:solid 2px;\">\n",
    "        <td style=\"border:solid 2px;\"> grad_boost_tunado.csv </td>\n",
    "        <td style=\"border:solid 2px;\"> 0.62201</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Faça a tunagem dos modelos Light GBM, XGBoost e CatBoost. Os scores tiveram melhoras?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Faça um stack dos 3 melhores modelos que você tunou. Os scores tiveram melhoras?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Simulado! Nossa próxima atividade avaliativa será sobre classificação supervisionada. Faremos uma simulação usando o Titanic! Qual seria sua nota?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suponha que seu score é S:\n",
    "\n",
    "- Se S < 0.67, seus pontos seriam (1 - (S - 0.67)/0.67) * 4\n",
    "- Se 0.67 <= S <= 0.73, seus pontos seriam proporcionais no intervalo de 4 a 7.\n",
    "- Se 0.73 <= S <= 0.81, seus pontos seriam proporcionais no intervalo de 7 a 10.\n",
    "\n",
    "Boa sorte no simulado!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Fontes</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/ihelon/titanic-hyperparameter-tuning-with-gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
