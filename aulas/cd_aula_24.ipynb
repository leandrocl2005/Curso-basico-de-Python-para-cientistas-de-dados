{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "336bc8b5",
      "metadata": {
        "id": "336bc8b5"
      },
      "source": [
        "# Word Embeeding e LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cb1b29d",
      "metadata": {
        "id": "2cb1b29d"
      },
      "source": [
        "Quando os dados são textos, devemos de alguma forma transformar estes em vetores numéricos para que a maioria dos modelos possam ser treinados. Veremos algumas formas de vetorizar texto."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80000ef2",
      "metadata": {
        "id": "80000ef2"
      },
      "source": [
        "Utilizaremos dados do Twitter que podem ser baixados em:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99b88fd9",
      "metadata": {
        "id": "99b88fd9"
      },
      "source": [
        "- https://www.kaggle.com/datasets/kazanova/sentiment140\n",
        "- target: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "eab3cab5",
      "metadata": {
        "id": "eab3cab5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# texto\n",
        "import re\n",
        "import string\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from nltk.tokenize import word_tokenize # Slow!\n",
        "from nltk import PorterStemmer\n",
        "from nltk import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# modelo\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "# métricas\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# utils\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# keras\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, Input, Flatten, GRU, Dense, LSTM, Bidirectional\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model, Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e8787676",
      "metadata": {
        "id": "e8787676"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\n",
        "    \"../datasets/Tweets/tweets.csv\", encoding='latin-1',\n",
        "    names=[\"Sentiment\", \"ID\", \"Date\", \"Query\", \"User\", \"Tweet\"]\n",
        ")\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5943697a",
      "metadata": {
        "id": "5943697a"
      },
      "source": [
        "## Limpeza de dados textuais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce4eb04b",
      "metadata": {
        "id": "ce4eb04b"
      },
      "outputs": [],
      "source": [
        "# removendo colunas desnecessárias\n",
        "df.drop(['ID', 'Date', 'Query', 'User'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ec76e86",
      "metadata": {
        "id": "9ec76e86"
      },
      "outputs": [],
      "source": [
        "# deixando todos os caracteres minúsculos\n",
        "df['Tweet'] = df['Tweet'].map(str.lower)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "227d8c0a",
      "metadata": {
        "id": "227d8c0a"
      },
      "outputs": [],
      "source": [
        "# removendo pontuações e marcações de usuários\n",
        "def RemovePunctuation(x):\n",
        "    x = ' '.join(re.sub(\"(@[A-Za-z0-9]+)\",\" \",x).split())\n",
        "    return re.sub(\"[\"+string.punctuation+\"]\", r\" \", x)\n",
        "df['Tweet'] = df['Tweet'].map(RemovePunctuation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f86d1521",
      "metadata": {
        "id": "f86d1521"
      },
      "outputs": [],
      "source": [
        "# removendo números\n",
        "def RemoveNumbers(x):\n",
        "    res = re.sub(r'[0-9]+',r' ',x)\n",
        "    return res\n",
        "df['Tweet'] = df['Tweet'].map(RemoveNumbers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5681c5f",
      "metadata": {
        "id": "f5681c5f"
      },
      "outputs": [],
      "source": [
        "# removendo stopwords\n",
        "df['Tweet'] = df['Tweet'].map(remove_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59549b53",
      "metadata": {
        "id": "59549b53"
      },
      "outputs": [],
      "source": [
        "# removendo caracteres isolados\n",
        "def removeSingleChars(text):\n",
        "    words = text.split()\n",
        "    return \" \".join([w for w in words if len(w) > 1])\n",
        "df['Tweet'] = df['Tweet'].map(removeSingleChars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a0e174c",
      "metadata": {
        "id": "5a0e174c"
      },
      "outputs": [],
      "source": [
        "### PULAR ###\n",
        "\n",
        "# extraindo a raiz da palavra\n",
        "# para português: # st = nltk.SnowballStemmer('portuguese')\n",
        "# Lemmatization vs Stemmering (Lemma is a word)\n",
        "\n",
        "st = PorterStemmer()\n",
        "def stemming_on_text(data):\n",
        "    data_split = data.split()\n",
        "    text = [st.stem(word) for word in data_split]\n",
        "    return text\n",
        "df['Tweet']= df['Tweet'].map(stemming_on_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6d430ff",
      "metadata": {
        "id": "d6d430ff",
        "outputId": "b8a1e81c-68d6-4885-d7c2-6d2282c082bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0          [http, twitpic, com, zl, awww, bummer, shoulda...\n",
              "1          [upset, update, facebook, texting, result, sch...\n",
              "2            [dived, time, ball, managed, save, rest, bound]\n",
              "3                                  [body, feel, itchy, like]\n",
              "4                                            [behaving, mad]\n",
              "                                 ...                        \n",
              "1599995                [woke, having, school, best, feeling]\n",
              "1599996    [thewdb, com, cool, hear, old, walt, interview...\n",
              "1599997                 [ready, mojo, makeover, ask, detail]\n",
              "1599998    [happy, th, birthday, boo, alll, time, tupac, ...\n",
              "1599999                              [happy, charitytuesday]\n",
              "Name: Tweet, Length: 1600000, dtype: object"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lm = WordNetLemmatizer()\n",
        "def lemmatizer_on_text(data):\n",
        "    data_split = data.split()\n",
        "    text = [lm.lemmatize(word) for word in data_split]\n",
        "    return text\n",
        "df['Tweet'].map(lemmatizer_on_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dda32dd6",
      "metadata": {
        "id": "dda32dd6"
      },
      "outputs": [],
      "source": [
        "df.to_csv('../datasets/Tweets/clean_tweets.csv', index=None, encoding=\"utf-8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23aacf84",
      "metadata": {
        "id": "23aacf84"
      },
      "source": [
        "## Limpando a memória"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "913428cd",
      "metadata": {
        "id": "913428cd",
        "outputId": "ebd6e03f-4693-4da2-8f57-18b24628df48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                             X: 691.3 MiB\n",
            "                       X_train: 656.7 MiB\n",
            "                        X_test: 34.6 MiB\n",
            "                             y: 24.3 MiB\n",
            "                       y_train: 23.0 MiB\n",
            "                     all_words:  8.0 MiB\n",
            "                        y_test:  1.2 MiB\n",
            "                        y_pred: 621.0 KiB\n",
            "                           _14:  2.4 KiB\n",
            "                           _15:  2.4 KiB\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "def sizeof_fmt(num, suffix='B'):\n",
        "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
        "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
        "        if abs(num) < 1024.0:\n",
        "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
        "        num /= 1024.0\n",
        "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
        "\n",
        "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in list(\n",
        "                          locals().items())), key= lambda x: -x[1])[:10]:\n",
        "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b2a2905",
      "metadata": {
        "id": "3b2a2905"
      },
      "outputs": [],
      "source": [
        "del X\n",
        "del X_train\n",
        "del X_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bacc0f0e",
      "metadata": {
        "id": "bacc0f0e"
      },
      "source": [
        "## Continuando ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1428b684",
      "metadata": {
        "id": "1428b684"
      },
      "source": [
        "# Vetorização com TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10586408",
      "metadata": {
        "id": "10586408"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('../datasets/Tweets/clean_tweets.csv')\n",
        "df.dropna(inplace=True)\n",
        "X = df['Tweet']\n",
        "y = df['Sentiment']\n",
        "del df\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.05, random_state =42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db2769ab",
      "metadata": {
        "id": "db2769ab"
      },
      "source": [
        "https://towardsdatascience.com/tf-term-frequency-idf-inverse-document-frequency-from-scratch-in-python-6c2b61b78558"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef11194a",
      "metadata": {
        "id": "ef11194a",
        "outputId": "3471d31e-a025-4a9e-e197-3c88c5aa0ecb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=500000, ngram_range=(1, 2))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=500000, ngram_range=(1, 2))</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "TfidfVectorizer(max_features=500000, ngram_range=(1, 2))"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%% time\n",
        "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
        "vectoriser.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb52ee3c",
      "metadata": {
        "id": "eb52ee3c"
      },
      "outputs": [],
      "source": [
        "%% time\n",
        "X_train = vectoriser.transform(X_train)\n",
        "X_test  = vectoriser.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f54e95c2",
      "metadata": {
        "id": "f54e95c2",
        "outputId": "2f11c4fe-1afd-4f2e-8b2d-69fa8482300f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "BernoulliNB()"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BNBmodel = BernoulliNB()\n",
        "BNBmodel.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e9eb230",
      "metadata": {
        "id": "6e9eb230",
        "outputId": "501cf722-b680-45ec-beb8-ae3cd5a43e72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.78      0.77     39447\n",
            "           4       0.78      0.77      0.77     40033\n",
            "\n",
            "    accuracy                           0.77     79480\n",
            "   macro avg       0.77      0.77      0.77     79480\n",
            "weighted avg       0.77      0.77      0.77     79480\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = BNBmodel.predict(X_test)\n",
        "print(classification_report(y_pred, y_test)) # 77%"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27711d62",
      "metadata": {
        "id": "27711d62"
      },
      "source": [
        "## Vetorização com OneHot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4e0a462b",
      "metadata": {
        "id": "4e0a462b"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('../datasets/Tweets/clean_tweets.csv')\n",
        "df.dropna(inplace=True)\n",
        "X = df['Tweet']\n",
        "y = df['Sentiment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ef3f1492",
      "metadata": {
        "id": "ef3f1492"
      },
      "outputs": [],
      "source": [
        "all_words = set()\n",
        "for row in df['Tweet'].values:\n",
        "    for word in row.split():\n",
        "        all_words.add(word)\n",
        "len(all_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "150c62b3",
      "metadata": {
        "id": "150c62b3",
        "outputId": "de7cd833-6a44-489e-ecc8-76233d260c5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 8.36 s\n",
            "Wall time: 11.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# não haverá unicidade com 500\n",
        "# mesma palavra mesmo encoding (não considera contexto)\n",
        "# vetor muito grande se unicidade\n",
        "df[\"Tweet\"] = df[\"Tweet\"].map(lambda x: one_hot(x, 500))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c00c67f",
      "metadata": {
        "id": "5c00c67f",
        "outputId": "6d0f796a-5c59-4b16-fae5-5b3020c912ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    [19, 151, 310, 370, 355, 200, 49, 304, 373, 31...\n",
              "1             [271, 111, 282, 136, 318, 401, 346, 311]\n",
              "2                    [379, 362, 265, 401, 499, 34, 47]\n",
              "3                                  [347, 155, 192, 28]\n",
              "4                                            [312, 62]\n",
              "Name: Tweet, dtype: object"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"Tweet\"].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f92b6abd",
      "metadata": {
        "id": "f92b6abd",
        "outputId": "bf3da040-fd5e-4772-cc71-1eb75fc9d102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "114 1\n"
          ]
        }
      ],
      "source": [
        "df[\"Tweet_count_words\"] = df[\"Tweet\"].map(len)\n",
        "print(df['Tweet_count_words'].max(), df['Tweet_count_words'].min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "656052c2",
      "metadata": {
        "id": "656052c2"
      },
      "outputs": [],
      "source": [
        "X = pad_sequences(\n",
        "    df[\"Tweet\"],\n",
        "    maxlen=114,\n",
        "    padding='post',\n",
        "    truncating='post',\n",
        "    value=0.0)\n",
        "y = df['Sentiment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e2b9344",
      "metadata": {
        "id": "8e2b9344",
        "outputId": "737bd561-2faf-40f0-df30-7f7f63d027d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 19, 151, 310, 370, 355, 200,  49, 304, 373, 310,  46,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [271, 111, 282, 136, 318, 401, 346, 311,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a0ca85b",
      "metadata": {
        "id": "6a0ca85b"
      },
      "outputs": [],
      "source": [
        "del df\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.05, random_state =42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "184164c5",
      "metadata": {
        "id": "184164c5",
        "outputId": "a193561a-98f7-4abf-e170-7f6b6967fb86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.50      0.55     46864\n",
            "           4       0.41      0.50      0.46     32616\n",
            "\n",
            "    accuracy                           0.50     79480\n",
            "   macro avg       0.50      0.50      0.50     79480\n",
            "weighted avg       0.52      0.50      0.51     79480\n",
            "\n"
          ]
        }
      ],
      "source": [
        "BNBmodel = BernoulliNB()\n",
        "BNBmodel.fit(X_train, y_train)\n",
        "y_pred = BNBmodel.predict(X_test)\n",
        "print(classification_report(y_pred, y_test)) # 77%"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "678b4efe",
      "metadata": {
        "id": "678b4efe"
      },
      "source": [
        "## Exercícios"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15afeec4",
      "metadata": {
        "id": "15afeec4"
      },
      "source": [
        "Resolva o mesmo problema transformando textos com as duas técnicas abaixo:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a88bfdb",
      "metadata": {
        "id": "5a88bfdb"
      },
      "source": [
        "Count vectorizing (1,2 Ngrams), Bag of words e One Hot Encoding N-Grams\n",
        "- https://medium.com/analytics-vidhya/fundamentals-of-bag-of-words-and-tf-idf-9846d301ff22"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb43baf5",
      "metadata": {
        "id": "eb43baf5"
      },
      "source": [
        "## Vetorização com Embeedings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21014c9e",
      "metadata": {
        "id": "21014c9e"
      },
      "source": [
        "https://www.kaggle.com/code/rajmehra03/a-detailed-explanation-of-keras-embedding-layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d306acd2",
      "metadata": {
        "id": "d306acd2"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('clean_tweets.csv')\n",
        "df.dropna(inplace=True)\n",
        "X = df['Tweet']\n",
        "y = df['Sentiment'].map({0:0, 4:1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "92ac4f14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92ac4f14",
        "outputId": "81f9d942-4e18-43b0-8912-1fdfc6633fb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "314082"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "all_words = set()\n",
        "for row in df['Tweet'].values:\n",
        "    for word in row.split():\n",
        "        all_words.add(word)\n",
        "len(all_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3d879f2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d879f2f",
        "outputId": "0a601cb4-3512-4e87-f45a-c04960bb81b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "362 2\n"
          ]
        }
      ],
      "source": [
        "df[\"Tweet_count_words\"] = df[\"Tweet\"].map(len)\n",
        "print(df['Tweet_count_words'].max(), df['Tweet_count_words'].min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e774ec9e",
      "metadata": {
        "id": "e774ec9e"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.05, random_state =42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d704ee2d",
      "metadata": {
        "id": "d704ee2d"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6e85f2b9",
      "metadata": {
        "id": "6e85f2b9"
      },
      "outputs": [],
      "source": [
        "word_index=tokenizer.word_index\n",
        "vocab_size = len(word_index)+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f2b5fa20",
      "metadata": {
        "id": "f2b5fa20"
      },
      "outputs": [],
      "source": [
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ff8bc398",
      "metadata": {
        "id": "ff8bc398"
      },
      "outputs": [],
      "source": [
        "maxlen = 100\n",
        "X_train_pad = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test_pad = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "495078d4",
      "metadata": {
        "id": "495078d4"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Embedding(vocab_size, 20, input_length=maxlen),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dense(10, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# compiles model\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d0e1ab9f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0e1ab9f",
        "outputId": "9f27399a-5ba0-481a-badb-06c2bd61736d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "2950/2950 [==============================] - 118s 38ms/step - loss: 0.4782 - accuracy: 0.7699\n",
            "Epoch 2/2\n",
            "2950/2950 [==============================] - 58s 20ms/step - loss: 0.4289 - accuracy: 0.8007\n",
            "CPU times: user 2min 37s, sys: 5.75 s, total: 2min 42s\n",
            "Wall time: 2min 56s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c7a63f8dcc0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "%%time\n",
        "model.fit(X_train_pad, y_train, batch_size=512, epochs=2, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "13601742",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13601742",
        "outputId": "a60cf760-feaf-437c-c1d8-e3ff7e7bf093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2484/2484 [==============================] - 12s 5ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.78      0.79      0.78     39349\n",
            "         1.0       0.79      0.78      0.78     40131\n",
            "\n",
            "    accuracy                           0.78     79480\n",
            "   macro avg       0.78      0.78      0.78     79480\n",
            "weighted avg       0.78      0.78      0.78     79480\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test_pad)\n",
        "print(classification_report(y_pred.ravel().round(0), y_test)) # 77%"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8b5b94f",
      "metadata": {
        "id": "d8b5b94f"
      },
      "source": [
        "- https://www.analyticsvidhya.com/blog/2022/01/sentiment-analysis-with-lstm/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98fd96ac",
      "metadata": {
        "id": "98fd96ac"
      },
      "source": [
        "# Atividade avaliativa"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a592bab",
      "metadata": {
        "id": "0a592bab"
      },
      "source": [
        "Faça uma submissão no desafio https://www.kaggle.com/competitions/dogs-vs-cats-redux-kernels-edition/submissions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be940564",
      "metadata": {
        "id": "be940564"
      },
      "source": [
        "- **Meta 10**: 0.4\n",
        "- **Meta 07**: 1.2\n",
        "- **Meta 04**: 7\n",
        "- **Meta 00**: >= 18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7daaa14a",
      "metadata": {
        "id": "7daaa14a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}